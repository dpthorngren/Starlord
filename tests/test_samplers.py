import re
from pathlib import Path

import numpy as np
import pytest
# flake8: noqa
from test_grids import dummy_grids

import starlord
from starlord._config import config


@pytest.mark.flaky(reruns=3)
def test_grid_retrieval(dummy_grids: Path):
    config.grid_dir = dummy_grids
    starlord.GridGenerator.reload_grids()
    fitter = starlord.ModelBuilder(True)
    fitter.assign("foo", "dummy.v1 + c.offset")
    fitter.constraint("l.foo", "normal", [0.5, 0.1])
    fitter.constraint("dummy.g2", "normal", [0.5, 2.3])
    fitter.constraint("dummy.v2", "normal", [1.5, 1.3])
    fitter.prior("x", "uniform", [-5., 5.])
    fitter.prior("y", "uniform", [0.1, 10.0])

    # Check parameters (grid noted only after running)
    assert fitter._gen.params == ('p.x', 'p.y')
    assert fitter._gen.locals == ('l.dummy_g2', 'l.dummy_v1', 'l.dummy_v2', 'l.foo')
    assert fitter._gen.constants == ('c.offset',)
    # Extra generate to ensure removal of autogenerated components is working
    print(fitter.summary())
    code = fitter.generate()
    assert len(re.findall(r"l_dummy_v1 = ", code)) == 1
    assert fitter._gen.locals == ('l.dummy_g1', 'l.dummy_g2', 'l.dummy_v1', 'l.dummy_v2', 'l.foo')
    assert fitter._gen.constants == ('c.grid_dummy_v1', 'c.grid_dummy_v2', 'c.offset')
    results = fitter.run_sampler({'offset': 1.5})

    # Check that the results are reasonable
    stats = results.stats()
    assert np.all(np.isfinite(stats.cov))
    for s in [stats.mean, stats.p16, stats.p50, stats.p84]:
        assert -5. <= s[0] <= 5.
        assert 0.1 <= s[1] <= 10.
    assert 0. < stats.std[0] <= 10.
    assert 0 <= stats.std[1] <= 10.


@pytest.mark.flaky(reruns=3)
def test_retrieval(capsys: pytest.CaptureFixture):
    fitter = starlord.ModelBuilder(True, False)
    fitter.assign("blah", "p.foo")
    fitter.constraint("l.blah", "beta", [15., 25])
    fitter.prior("foo", "uniform", [0., 1.])
    fitter.expression("l.stuff = p.bar + c.offset")
    fitter.constraint("l.stuff", "normal", [5., 2])
    fitter.prior("bar", "normal", [0., 10.])

    # Test that the summaries were reasonable
    print(fitter.summary())
    captured = capsys.readouterr()
    assert "Variables" in captured.out

    # Check parameters
    paramSummary = re.search(r"^Params:\s+(.*)$", captured.out, flags=re.M)
    assert paramSummary is not None
    params = list(map(str.strip, paramSummary.group(1).split(",")))
    assert params == ['bar', 'foo']
    localSummary = re.search(r"^Locals:\s+(.*)$", captured.out, flags=re.M)
    assert localSummary is not None
    locals = list(map(str.strip, localSummary.group(1).split(",")))
    assert locals == ['blah', 'stuff']

    # Check that the summary prints properly (largely formats result.stats())
    results = fitter.run_sampler({'offset': 1.5})
    summary = results.summary().splitlines()
    assert len(summary) == 3
    assert summary[0].startswith("     Name")
    assert summary[1].startswith("   0")
    assert summary[2].startswith("   1")

    # Check against known mean, std
    stats = results.stats()
    # Normal distribution
    s = 1. / (1. / 2.**2 + 1. / 10.**2)
    assert stats.mean[0] == pytest.approx(-1.5 + s * (5. / 2.**2 + 0. / 10.**2), rel=.05)
    assert stats.std[0]**2 == pytest.approx(s, rel=.1)
    # Beta distribution
    assert stats.mean[1] == pytest.approx(15. / (15+25.), rel=.05)
    assert stats.std[1]**2 == pytest.approx(15. * 25. / ((15 + 25)**2 * (15.+25.+1.)), rel=.1)
